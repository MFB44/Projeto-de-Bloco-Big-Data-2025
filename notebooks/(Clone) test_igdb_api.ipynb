{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed105241-f2f8-46a3-9a49-241f6bc1900e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687e950f-a092-45cc-a9cb-43ecb326965f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit\n",
    "import pandas as pd\n",
    "import requests, time, threading\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d6a07af-687c-439e-a08e-a855cce7e1c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "ACCESS_TOKEN = os.getenv(\"ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3678f62-bc85-4b1e-9990-72895afba66c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "offset = 0\n",
    "step = 100\n",
    "max_offset = 1000\n",
    "\n",
    "def get_igdb_data():\n",
    "    global offset\n",
    "\n",
    "    headers = {\n",
    "        \"Client-ID\": CLIENT_ID,\n",
    "        \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    body = f\"\"\"\n",
    "        fields id, name, total_rating, total_rating_count, first_release_date,\n",
    "        game_type, rating, rating_count, summary, genres.name, platforms.name;\n",
    "        sort total_rating desc;\n",
    "        where total_rating != null & total_rating_count > 100;\n",
    "        limit {step};\n",
    "        offset {offset};\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://api.igdb.com/v4/games\"\n",
    "    response = requests.post(url, headers=headers, data=body)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro IGDB: {response.status_code} - {response.text}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = response.json()\n",
    "    pdf = pd.json_normalize(data)\n",
    "\n",
    "    if \"id\" in pdf.columns:\n",
    "        pdf[\"id\"] = pdf[\"id\"].astype(str)\n",
    "\n",
    "    # Converter listas em strings\n",
    "    pdf[\"genres\"] = pdf[\"genres\"].apply(lambda x: \", \".join([g[\"name\"] for g in x]) if isinstance(x, list) else None)\n",
    "    pdf[\"platforms\"] = pdf[\"platforms\"].apply(lambda x: \", \".join([p[\"name\"] for p in x]) if isinstance(x, list) else None)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "def stream_igdb_data():\n",
    "    global offset\n",
    "\n",
    "    while True:\n",
    "        pdf = get_igdb_data()\n",
    "\n",
    "        offset += step\n",
    "        if offset >= max_offset:\n",
    "            offset = 0\n",
    "\n",
    "        if not pdf.empty:\n",
    "            expected_columns = [\n",
    "                \"id\", \"name\", \"total_rating\", \"total_rating_count\", \"first_release_date\",\n",
    "                \"game_type\", \"rating\", \"rating_count\", \"summary\", \"genres\", \"platforms\"\n",
    "            ]\n",
    "\n",
    "            for col in expected_columns:\n",
    "                if col not in pdf.columns:\n",
    "                    pdf[col] = None\n",
    "\n",
    "            for col in [\"total_rating\", \"total_rating_count\", \"rating\", \"rating_count\"]:\n",
    "                pdf[col] = pd.to_numeric(pdf[col], errors='coerce')\n",
    "\n",
    "            pdf = pdf[expected_columns]\n",
    "\n",
    "            spark_df = spark.createDataFrame(pdf)\n",
    "            spark_df = spark_df.withColumn(\"ingestion_time\", lit(datetime.now().isoformat()))\n",
    "\n",
    "            spark_df.write.mode(\"append\").format(\"delta\").save(\"/mnt/raw/igdb/games\")\n",
    "\n",
    "            print(f\"Ingested {len(pdf)} records at {datetime.now().isoformat()}\")\n",
    "        else:\n",
    "            print(\"Nenhum dado retornado da API.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "# Iniciar ingestão contínua\n",
    "threading.Thread(target=stream_igdb_data).start()\n",
    "\n",
    "# Leitura contínua do Delta\n",
    "df_stream = spark.readStream.format(\"delta\").load(\"/mnt/raw/igdb/games\")\n",
    "\n",
    "df_stream.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be2f813-ec2f-4faa-b3f2-b03783bd6ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Este código foi usado pois haviam erros na criação da tabela e no salvamento dos dados, esta etapa criou uma tabela com os dados corretos e permitiu que o streaming funcionasse corretamente\n",
    "\n",
    "# pdf = get_igdb_data()\n",
    "# if not pdf.empty:\n",
    "#     pdf[\"id\"] = pdf[\"id\"].astype(str)\n",
    "#     spark_df = spark.createDataFrame(pdf)\n",
    "#     spark_df = spark_df.withColumn(\"ingestion_time\", lit(datetime.now().isoformat()))\n",
    "#     spark_df.write.mode(\"overwrite\").format(\"delta\").save(\"/mnt/raw/igdb/games\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcba57cb-22bb-4296-b111-5f03d81e6c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.read.format(\"delta\").load(\"/mnt/raw/igdb/games\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) test_igdb_api",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
